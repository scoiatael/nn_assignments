{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuel.transformers import ScaleAndShift, Cast, Flatten, Mapping\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme, ShuffledScheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuel.datasets.cifar10 import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OFFSET = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CIFAR10.default_transformers = (\n",
    "    (ScaleAndShift, [2.0 / 255.0, -1], {'which_sources': 'features'}),\n",
    "    (Cast, [np.float32], {'which_sources': 'features'}), \n",
    "    (Flatten, [], {'which_sources': 'features'}),\n",
    "    (Mapping, [lambda batch: (b.T for b in batch)], {}) )\n",
    "\n",
    "mnist_train = CIFAR10((\"train\",), subset=slice(None,OFFSET))\n",
    "#this stream will shuffle the MNIST set and return us batches of 100 examples\n",
    "mnist_train_stream = DataStream.default_stream(\n",
    "    mnist_train,\n",
    "    iteration_scheme=ShuffledScheme(mnist_train.num_examples, 100))\n",
    "                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The streams return batches containing (u'features', u'targets')\n",
      "Each training batch consits of a tuple containing:\n",
      " - an array of size (3072, 100) containing float32\n",
      " - an array of size (1, 100) containing uint8\n"
     ]
    }
   ],
   "source": [
    "print \"The streams return batches containing %s\" % (mnist_train_stream.sources,)\n",
    "\n",
    "print \"Each training batch consits of a tuple containing:\"\n",
    "for element in next(mnist_train_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist_validation = CIFAR10((\"train\",), subset=slice(OFFSET, None))\n",
    "\n",
    "# We will use larger portions for testing and validation\n",
    "# as these dont do a backward pass and reauire less RAM.\n",
    "mnist_validation_stream = DataStream.default_stream(\n",
    "    mnist_validation, iteration_scheme=SequentialScheme(mnist_validation.num_examples, 250))\n",
    "mnist_test = CIFAR10((\"test\",))\n",
    "mnist_test_stream = DataStream.default_stream(\n",
    "    mnist_test, iteration_scheme=SequentialScheme(mnist_test.num_examples, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation/test batches consits of tuples containing:\n",
      " - an array of size (3072, 250) containing float32\n",
      " - an array of size (1, 250) containing uint8\n"
     ]
    }
   ],
   "source": [
    "print \"Validation/test batches consits of tuples containing:\"\n",
    "for element in next(mnist_test_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_var = T.matrix('inputs')\n",
    "target_var = T.ivector('targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_in = lasagne.layers.InputLayer(shape=(None, 3072),\n",
    "                                     input_var=input_var)\n",
    "\n",
    "# Apply 20% dropout to the input data:\n",
    "l_in_drop = lasagne.layers.DropoutLayer(l_in, p=0.2)\n",
    "\n",
    "# Add a fully-connected layer of 800 units, using the linear rectifier, and\n",
    "# initializing weights with Glorot's scheme (which is the default anyway):\n",
    "l_hid1 = lasagne.layers.DenseLayer(\n",
    "            l_in_drop, num_units=800,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify,\n",
    "            W=lasagne.init.GlorotUniform())\n",
    "\n",
    "# We'll now add dropout of 50%:\n",
    "l_hid1_drop = lasagne.layers.DropoutLayer(l_hid1, p=0.5)\n",
    "\n",
    "# Another 800-unit layer:\n",
    "l_hid2 = lasagne.layers.DenseLayer(\n",
    "            l_hid1_drop, num_units=800,\n",
    "            nonlinearity=lasagne.nonlinearities.rectify)\n",
    "\n",
    "# 50% dropout again:\n",
    "l_hid2_drop = lasagne.layers.DropoutLayer(l_hid2, p=0.5)\n",
    "\n",
    "# Finally, we'll add the fully-connected output layer, of 10 softmax units:\n",
    "l_out = lasagne.layers.DenseLayer(\n",
    "            l_hid2_drop, num_units=10,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(\n",
    "            loss, params, learning_rate=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                            target_var)\n",
    "test_loss = test_loss.mean()\n",
    "# As a bonus, also create an expression for the classification accuracy:\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                      dtype=theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "# Compile a second function computing the validation loss and accuracy:\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "train_stream = mnist_train_stream\n",
    "validation_stream = mnist_validation_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100 took 9.651s\n",
      "  training loss:\t\t1.774503\n",
      "  validation loss:\t\t1.680264\n",
      "  validation accuracy:\t\t41.57 %\n",
      "Epoch 2 of 100 took 9.580s\n",
      "  training loss:\t\t1.714181\n",
      "  validation loss:\t\t1.670209\n",
      "  validation accuracy:\t\t41.91 %\n",
      "Epoch 3 of 100 took 9.659s\n",
      "  training loss:\t\t1.667159\n",
      "  validation loss:\t\t1.649553\n",
      "  validation accuracy:\t\t42.79 %\n",
      "Epoch 4 of 100 took 9.305s\n",
      "  training loss:\t\t1.636520\n",
      "  validation loss:\t\t1.638263\n",
      "  validation accuracy:\t\t43.01 %\n",
      "Epoch 5 of 100 took 9.279s\n",
      "  training loss:\t\t1.596853\n",
      "  validation loss:\t\t1.620578\n",
      "  validation accuracy:\t\t43.23 %\n",
      "Epoch 6 of 100 took 9.379s\n",
      "  training loss:\t\t1.569598\n",
      "  validation loss:\t\t1.595980\n",
      "  validation accuracy:\t\t44.06 %\n",
      "Epoch 7 of 100 took 9.879s\n",
      "  training loss:\t\t1.544576\n",
      "  validation loss:\t\t1.590123\n",
      "  validation accuracy:\t\t44.39 %\n",
      "Epoch 8 of 100 took 10.167s\n",
      "  training loss:\t\t1.517861\n",
      "  validation loss:\t\t1.565367\n",
      "  validation accuracy:\t\t45.07 %\n",
      "Epoch 9 of 100 took 9.639s\n",
      "  training loss:\t\t1.491641\n",
      "  validation loss:\t\t1.575210\n",
      "  validation accuracy:\t\t44.82 %\n",
      "Epoch 10 of 100 took 9.204s\n",
      "  training loss:\t\t1.470004\n",
      "  validation loss:\t\t1.545008\n",
      "  validation accuracy:\t\t46.43 %\n",
      "Epoch 11 of 100 took 9.271s\n",
      "  training loss:\t\t1.446829\n",
      "  validation loss:\t\t1.535504\n",
      "  validation accuracy:\t\t46.33 %\n",
      "Epoch 12 of 100 took 9.459s\n",
      "  training loss:\t\t1.427110\n",
      "  validation loss:\t\t1.543243\n",
      "  validation accuracy:\t\t46.15 %\n",
      "Epoch 13 of 100 took 9.320s\n",
      "  training loss:\t\t1.413913\n",
      "  validation loss:\t\t1.540584\n",
      "  validation accuracy:\t\t46.35 %\n",
      "Epoch 14 of 100 took 9.321s\n",
      "  training loss:\t\t1.370784\n",
      "  validation loss:\t\t1.522684\n",
      "  validation accuracy:\t\t46.67 %\n",
      "Epoch 15 of 100 took 10.101s\n",
      "  training loss:\t\t1.368788\n",
      "  validation loss:\t\t1.537640\n",
      "  validation accuracy:\t\t46.15 %\n",
      "Epoch 16 of 100 took 10.246s\n",
      "  training loss:\t\t1.342037\n",
      "  validation loss:\t\t1.521434\n",
      "  validation accuracy:\t\t46.70 %\n",
      "Epoch 17 of 100 took 10.014s\n",
      "  training loss:\t\t1.315085\n",
      "  validation loss:\t\t1.530693\n",
      "  validation accuracy:\t\t46.43 %\n",
      "Epoch 18 of 100 took 9.269s\n",
      "  training loss:\t\t1.298625\n",
      "  validation loss:\t\t1.518506\n",
      "  validation accuracy:\t\t46.68 %\n",
      "Epoch 19 of 100 took 9.324s\n",
      "  training loss:\t\t1.281339\n",
      "  validation loss:\t\t1.523390\n",
      "  validation accuracy:\t\t46.55 %\n",
      "Epoch 20 of 100 took 9.453s\n",
      "  training loss:\t\t1.269257\n",
      "  validation loss:\t\t1.517724\n",
      "  validation accuracy:\t\t47.02 %\n",
      "Epoch 21 of 100 took 8.930s\n",
      "  training loss:\t\t1.249416\n",
      "  validation loss:\t\t1.530642\n",
      "  validation accuracy:\t\t46.76 %\n",
      "Epoch 22 of 100 took 8.310s\n",
      "  training loss:\t\t1.230712\n",
      "  validation loss:\t\t1.497785\n",
      "  validation accuracy:\t\t47.82 %\n",
      "Epoch 23 of 100 took 10.010s\n",
      "  training loss:\t\t1.207098\n",
      "  validation loss:\t\t1.508869\n",
      "  validation accuracy:\t\t47.48 %\n",
      "Epoch 24 of 100 took 9.481s\n",
      "  training loss:\t\t1.180506\n",
      "  validation loss:\t\t1.521976\n",
      "  validation accuracy:\t\t46.98 %\n",
      "Epoch 25 of 100 took 9.895s\n",
      "  training loss:\t\t1.184659\n",
      "  validation loss:\t\t1.508358\n",
      "  validation accuracy:\t\t47.50 %\n",
      "Epoch 26 of 100 took 10.105s\n",
      "  training loss:\t\t1.160001\n",
      "  validation loss:\t\t1.503568\n",
      "  validation accuracy:\t\t47.85 %\n",
      "Epoch 27 of 100 took 9.170s\n",
      "  training loss:\t\t1.141789\n",
      "  validation loss:\t\t1.508948\n",
      "  validation accuracy:\t\t47.67 %\n",
      "Epoch 28 of 100 took 9.953s\n",
      "  training loss:\t\t1.121271\n",
      "  validation loss:\t\t1.509508\n",
      "  validation accuracy:\t\t47.40 %\n",
      "Epoch 29 of 100 took 9.637s\n",
      "  training loss:\t\t1.104030\n",
      "  validation loss:\t\t1.506413\n",
      "  validation accuracy:\t\t47.86 %\n",
      "Epoch 30 of 100 took 9.266s\n",
      "  training loss:\t\t1.094142\n",
      "  validation loss:\t\t1.493012\n",
      "  validation accuracy:\t\t48.08 %\n",
      "Epoch 31 of 100 took 8.647s\n",
      "  training loss:\t\t1.068435\n",
      "  validation loss:\t\t1.520315\n",
      "  validation accuracy:\t\t47.62 %\n",
      "Epoch 32 of 100 took 9.520s\n",
      "  training loss:\t\t1.071627\n",
      "  validation loss:\t\t1.505975\n",
      "  validation accuracy:\t\t48.25 %\n",
      "Epoch 33 of 100 took 8.797s\n",
      "  training loss:\t\t1.061653\n",
      "  validation loss:\t\t1.505227\n",
      "  validation accuracy:\t\t47.88 %\n",
      "Epoch 34 of 100 took 8.688s\n",
      "  training loss:\t\t1.031437\n",
      "  validation loss:\t\t1.511830\n",
      "  validation accuracy:\t\t48.08 %\n",
      "Epoch 35 of 100 took 9.561s\n",
      "  training loss:\t\t1.023737\n",
      "  validation loss:\t\t1.520683\n",
      "  validation accuracy:\t\t48.13 %\n",
      "Epoch 36 of 100 took 9.386s\n",
      "  training loss:\t\t1.010094\n",
      "  validation loss:\t\t1.520421\n",
      "  validation accuracy:\t\t47.80 %\n",
      "Epoch 37 of 100 took 8.960s\n",
      "  training loss:\t\t1.002161\n",
      "  validation loss:\t\t1.525803\n",
      "  validation accuracy:\t\t48.09 %\n",
      "Epoch 38 of 100 took 8.975s\n",
      "  training loss:\t\t0.963761\n",
      "  validation loss:\t\t1.524714\n",
      "  validation accuracy:\t\t48.54 %\n",
      "Epoch 39 of 100 took 8.800s\n",
      "  training loss:\t\t0.971437\n",
      "  validation loss:\t\t1.555620\n",
      "  validation accuracy:\t\t47.46 %\n",
      "Epoch 40 of 100 took 9.919s\n",
      "  training loss:\t\t0.951102\n",
      "  validation loss:\t\t1.540680\n",
      "  validation accuracy:\t\t47.94 %\n",
      "Epoch 41 of 100 took 9.284s\n",
      "  training loss:\t\t0.929762\n",
      "  validation loss:\t\t1.530595\n",
      "  validation accuracy:\t\t48.51 %\n",
      "Epoch 42 of 100 took 8.958s\n",
      "  training loss:\t\t0.936724\n",
      "  validation loss:\t\t1.556494\n",
      "  validation accuracy:\t\t47.93 %\n",
      "Epoch 43 of 100 took 9.084s\n",
      "  training loss:\t\t0.921582\n",
      "  validation loss:\t\t1.535683\n",
      "  validation accuracy:\t\t48.38 %\n",
      "Epoch 44 of 100 took 9.602s\n",
      "  training loss:\t\t0.911411\n",
      "  validation loss:\t\t1.546656\n",
      "  validation accuracy:\t\t47.96 %\n",
      "Epoch 45 of 100 took 9.568s\n",
      "  training loss:\t\t0.892715\n",
      "  validation loss:\t\t1.556712\n",
      "  validation accuracy:\t\t48.29 %\n",
      "Epoch 46 of 100 took 9.567s\n",
      "  training loss:\t\t0.881940\n",
      "  validation loss:\t\t1.560124\n",
      "  validation accuracy:\t\t47.76 %\n",
      "Epoch 47 of 100 took 9.721s\n",
      "  training loss:\t\t0.861146\n",
      "  validation loss:\t\t1.567444\n",
      "  validation accuracy:\t\t48.55 %\n",
      "Epoch 48 of 100 took 9.181s\n",
      "  training loss:\t\t0.867067\n",
      "  validation loss:\t\t1.571225\n",
      "  validation accuracy:\t\t48.13 %\n",
      "Epoch 49 of 100 took 9.532s\n",
      "  training loss:\t\t0.842284\n",
      "  validation loss:\t\t1.570668\n",
      "  validation accuracy:\t\t48.19 %\n",
      "Epoch 50 of 100 took 9.602s\n",
      "  training loss:\t\t0.832068\n",
      "  validation loss:\t\t1.586736\n",
      "  validation accuracy:\t\t48.18 %\n",
      "Epoch 51 of 100 took 9.480s\n",
      "  training loss:\t\t0.850712\n",
      "  validation loss:\t\t1.571315\n",
      "  validation accuracy:\t\t48.63 %\n",
      "Epoch 52 of 100 took 9.643s\n",
      "  training loss:\t\t0.822510\n",
      "  validation loss:\t\t1.574920\n",
      "  validation accuracy:\t\t48.42 %\n",
      "Epoch 53 of 100 took 9.753s\n",
      "  training loss:\t\t0.793140\n",
      "  validation loss:\t\t1.574840\n",
      "  validation accuracy:\t\t48.74 %\n",
      "Epoch 54 of 100 took 9.810s\n",
      "  training loss:\t\t0.797433\n",
      "  validation loss:\t\t1.611306\n",
      "  validation accuracy:\t\t48.58 %\n",
      "Epoch 55 of 100 took 8.999s\n",
      "  training loss:\t\t0.789395\n",
      "  validation loss:\t\t1.596406\n",
      "  validation accuracy:\t\t48.30 %\n",
      "Epoch 56 of 100 took 9.398s\n",
      "  training loss:\t\t0.773695\n",
      "  validation loss:\t\t1.611687\n",
      "  validation accuracy:\t\t48.18 %\n",
      "Epoch 57 of 100 took 9.731s\n",
      "  training loss:\t\t0.757019\n",
      "  validation loss:\t\t1.603993\n",
      "  validation accuracy:\t\t48.27 %\n",
      "Epoch 58 of 100 took 9.624s\n",
      "  training loss:\t\t0.759899\n",
      "  validation loss:\t\t1.628046\n",
      "  validation accuracy:\t\t48.22 %\n",
      "Epoch 59 of 100 took 9.413s\n",
      "  training loss:\t\t0.744322\n",
      "  validation loss:\t\t1.626519\n",
      "  validation accuracy:\t\t48.15 %\n",
      "Epoch 60 of 100 took 8.960s\n",
      "  training loss:\t\t0.742832\n",
      "  validation loss:\t\t1.623249\n",
      "  validation accuracy:\t\t48.61 %\n",
      "Epoch 61 of 100 took 9.071s\n",
      "  training loss:\t\t0.712177\n",
      "  validation loss:\t\t1.646024\n",
      "  validation accuracy:\t\t48.40 %\n",
      "Epoch 62 of 100 took 8.906s\n",
      "  training loss:\t\t0.733991\n",
      "  validation loss:\t\t1.634836\n",
      "  validation accuracy:\t\t48.86 %\n",
      "Epoch 63 of 100 took 8.890s\n",
      "  training loss:\t\t0.723155\n",
      "  validation loss:\t\t1.634638\n",
      "  validation accuracy:\t\t48.22 %\n",
      "Epoch 64 of 100 took 8.671s\n",
      "  training loss:\t\t0.710649\n",
      "  validation loss:\t\t1.649386\n",
      "  validation accuracy:\t\t48.48 %\n",
      "Epoch 65 of 100 took 8.770s\n",
      "  training loss:\t\t0.711963\n",
      "  validation loss:\t\t1.633693\n",
      "  validation accuracy:\t\t48.55 %\n",
      "Epoch 66 of 100 took 9.315s\n",
      "  training loss:\t\t0.689806\n",
      "  validation loss:\t\t1.653413\n",
      "  validation accuracy:\t\t49.03 %\n",
      "Epoch 67 of 100 took 8.958s\n",
      "  training loss:\t\t0.680762\n",
      "  validation loss:\t\t1.647734\n",
      "  validation accuracy:\t\t48.84 %\n",
      "Epoch 68 of 100 took 8.954s\n",
      "  training loss:\t\t0.698880\n",
      "  validation loss:\t\t1.657227\n",
      "  validation accuracy:\t\t48.80 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-f72a0c51ea05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_epoch_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtrain_err\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mtrain_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i247926/.local/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for inputs, targets in train_stream.get_epoch_iterator():\n",
    "        train_err += train_fn(inputs.T, targets.ravel())\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in validation_stream.get_epoch_iterator():\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs.T, targets.ravel())\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
